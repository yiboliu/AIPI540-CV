{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
      ],
      "metadata": {
        "id": "Auyy1XpUPdmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ql90Ie0cPOYt"
      },
      "outputs": [],
      "source": [
        "import detectron2\n",
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog, detection_utils\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.data.transforms import ResizeTransform\n",
        "from detectron2.structures import BoxMode\n",
        "from detectron2.evaluation import COCOEvaluator\n",
        "import json\n",
        "import csv\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import random_split\n",
        "from torchvision.datasets import MNIST\n",
        "import cv2\n",
        "import os\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5FeGgq9fSYV",
        "outputId": "183344e3-b39a-4968-9d4d-fd61b046f9c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch:  2.0 ; cuda:  cu118\n"
          ]
        }
      ],
      "source": [
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X00CcsVhfjyJ"
      },
      "outputs": [],
      "source": [
        "def process_bbox(bbox):\n",
        "  substr = bbox[1:len(bbox) - 1]\n",
        "  nums = substr.split(', ')\n",
        "  ret = []\n",
        "  for i in nums:\n",
        "    ret.append(int(float(i) * 0.25))\n",
        "  return ret\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encountered some bugs using ResizeTransform directly in modeling, so I switched to thsi approach: resize the pictures as a standalone function and save the resized pictures in the workspace\n",
        "def resize_images():\n",
        "  filepath = 'train.csv'\n",
        "  with open(filepath, 'r') as f:\n",
        "    reader = csv.DictReader(f)\n",
        "    cnt = 0\n",
        "    visited=set()\n",
        "\n",
        "    for row in reader:\n",
        "      if row['image_id'] in visited:\n",
        "        continue\n",
        "      visited.add(row['image_id'])\n",
        "      resize = ResizeTransform(new_h=256, new_w=256, h=1024, w=1024)\n",
        "      image = resize.apply_image(cv2.imread(get_image_path(row['image_id'])))\n",
        "      filename = os.path.join('resized', f\"{row['image_id']}.jpg\")\n",
        "      cv2.imwrite(filename, image)\n",
        "      cnt+=1"
      ],
      "metadata": {
        "id": "5bRqN-IBaLwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8w9RIdQf4XM"
      },
      "outputs": [],
      "source": [
        "def get_image_path(image_id):\n",
        "  return f'train/{image_id}.jpg'\n",
        "\n",
        "def scale(magnitude, origin, new):\n",
        "  return int(magnitude * (new/origin))\n",
        "\n",
        "def generate_annotations2():\n",
        "  filepath = 'train.csv'\n",
        "  result = []\n",
        "  with open(filepath, 'r') as f:\n",
        "    reader = csv.DictReader(f)\n",
        "\n",
        "    for row in reader:\n",
        "      bbox = process_bbox(row['bbox'])\n",
        "\n",
        "      annotation = {\n",
        "          'bbox': bbox,\n",
        "          'bbox_mode': BoxMode.XYWH_ABS,\n",
        "          'category_id': 0,\n",
        "          'category': 'wheat',\n",
        "          'image_id': row['image_id'],\n",
        "      }\n",
        "\n",
        "      # if the current row has the same image_id as the preivous one, then just append the annotation to the previous one, avoiding duplication\n",
        "      if result and row['image_id'] == result[-1]['image_id']:\n",
        "        result[-1]['annotations'].append(annotation)\n",
        "        continue\n",
        "\n",
        "      height = scale(float(row['height']), 1024, 256)\n",
        "      width = scale(float(row['width']), 1024, 256)\n",
        "      image_path = f'resized/{row['image_id']}.jpg'\n",
        "      image = cv2.imread(image_path)\n",
        "\n",
        "      image_data = {\n",
        "          'file_name': image_path,\n",
        "          'image_id': row['image_id'],\n",
        "          'height': height,\n",
        "          'width': width,\n",
        "          'image': image,\n",
        "          'annotations': [annotation]\n",
        "      }\n",
        "      result.append(image_data)\n",
        "\n",
        "  return result\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def register_data():\n",
        "  DatasetCatalog.clear()\n",
        "  MetadataCatalog.clear()\n",
        "  DatasetCatalog.register('training_dataset2', generate_annotations2)\n",
        "  MetadataCatalog.get('training_dataset2').set(thing_classes=['wheat'])\n",
        "\n",
        "  # taking 80% as the training data and rest as validation data\n",
        "  overall = DatasetCatalog.get('training_dataset2')\n",
        "  train_len = 0.8 * len(overall)\n",
        "  train_data, val_data = torch.utils.data.random_split(overall, [train_len, len(overall) - train_len])\n",
        "  train_data_name = 'train_data'\n",
        "  val_data_name = 'tune_data' # an interesting problem, seems like DefaultTrainer doesn't take words starting with 'v', so I changed 'val_data' to 'tune_data'\n",
        "\n",
        "  DatasetCatalog.register(train_data_name, lambda: train_data)\n",
        "  MetadataCatalog.get(train_data_name).set(thing_classes=['wheat'])\n",
        "\n",
        "  DatasetCatalog.register(val_data_name, lambda: val_data)\n",
        "  MetadataCatalog.get(val_data_name).set(thing_classes=['wheat'])"
      ],
      "metadata": {
        "id": "HD_r-w9pYwq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jl-2BapDIhJu"
      },
      "outputs": [],
      "source": [
        "# The purpose of creating this custom trainer is to enable it using validation data\n",
        "class MyTrainer(DefaultTrainer):\n",
        "\n",
        "  @classmethod\n",
        "  def build_evaluator(cls, cfg, dataset_name='tune_data'):\n",
        "    return COCOEvaluator(dataset_name, cfg, False, output_dir='out')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_save_model():\n",
        "  cfg = get_cfg()\n",
        "  cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")) # choose faster rcnn as I don't have ground truth masks in the training data\n",
        "  cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")\n",
        "  cfg.SOLVER.OPTIMIZER = \"Adam\"  # tried with SGD originally, wasn't satisfying\n",
        "  cfg.SOLVER.ADAM = True\n",
        "  cfg.SOLVER.ADAM_BETAS = (0.9, 0.999)\n",
        "  cfg.SOLVER.ADAM_EPSILON = 1e-08\n",
        "  cfg.SOLVER.BASE_LR = 0.001\n",
        "  cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1 # only one class wheat\n",
        "  cfg.SOLVER.MAX_ITER = 675 #\n",
        "  cfg.SOLVER.IMS_PER_BATCH = 4 # tried with 2 initially, was too slow\n",
        "  cfg.TEST.EVAL_PERIOD = 300\n",
        "  cfg.DATASETS.TRAIN = (train_data_name,)\n",
        "  cfg.DATASETS.TEST = (val_data_name,)\n",
        "\n",
        "  trainer = MyTrainer(cfg)\n",
        "  trainer.resume_or_load(resume=False)\n",
        "\n",
        "  trainer.train()\n",
        "\n",
        "  # save the model for later use\n",
        "  save_path = \"model.pth\"\n",
        "  torch.save(trainer.state_dict(), save_path)\n",
        "  files.download(save_path)\n",
        "\n",
        "# This takes way too long to train and has too long logs, so I just paste the logs from last line: fast_rcnn/cls_accuracy: 0.8876953125, total_loss: 0.9084931015968323"
      ],
      "metadata": {
        "id": "O8g1YRImbfSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resize_images()\n",
        "!zip -r resized.zip resized\n",
        "from google.colab import files\n",
        "files.download('resized.zip') # save the resized images for later use\n",
        "\n",
        "register_data()\n",
        "train_data()"
      ],
      "metadata": {
        "id": "fzcYt51Yb5g_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}